\section{Escape from \DDAALLEE\ 2}
\label{sec:escape}

As hands-on counterpoint to the previous analytical sections, I performed a
series of hands-on experiments probing \DALLE. \S\ref{sec:crucifixion}
determines the reason for my first prompt's rejection, and \S\ref{sec:strategy}
presents an effective strategy for working around its aggressive censor. Both
series of experiments are complicated by the same critical restriction: Avoid
content warnings! More specifically, I guessed (correctly) that OpenAI would
tolerate the occasional warning. But too many warnings in too little time surely
would lead to account suspension, which they do~\cite{SpicyElephant2022}. The
practical implication is that the collection of empirical evidence must be
distributed over people, as in \S\ref{sec:crucifixion}, or over time, as in
\S\ref{sec:strategy}.


\subsection{About That Rejected Prompt}
\label{sec:crucifixion}

In the waning days of 2021, I got to play with a text-to-image system for the
first time. Compared to \DALLE\ or Stable Diffusion, inference was much slower
and image resolution was much lower. Since the public instance was also
oversubscribed, it usually took hours before results were available.
Nonetheless, the system already exhibited a similar ability to conjure rich
imagery out of a few words. I was particularly impressed by this prompt:

\begin{quote}
\openfat{}The crucified pope, painting by Francis Bacon\closefat{}
\end{quote}

\noindent{}Since I wanted to compare results, this also was my first, rejected
prompt for \DALLE. Admittedly, it might not be G-rated, as OpenAI requires. But
it certainly should not be prohibited either. Francis Bacon is one of the most
famous 20\textsuperscript{th} century painters. The pope and the crucifixion are
two of the painter's four major themes~\cite{Wikipedia2023}. More generally, the
crucifixion of Christ is of critical liturgical importance to Christianity, only
the largest religion in the world. Paintings and statues of the crucified Jesus
are ubiquitous in churches and art museums alike.

After a review of the content policy, I was able to narrow down the likely cause
by dismissing all prohibitions except \emph{violence}, e.g., the crucifixion
itself, and \emph{shocking content}, i.e., thusly subjugating the leader of a
major branch of Christianity. Eliminating the second hypothesis took little
effort besides patience thanks to the \DALLE\ 2 subreddit. The forum aggregates
many prompts and resulting images from a large number of users, thus reflecting
a wide range of interests and obsessions. While perusing the posts, I noticed a
couple religiously themed ones and realized that, instead of running experiments
myself or recruiting others to spread the risk, I could just monitor the posts.

Sure enough, over the months, users shared quite the range of prompts and images
with a distinctly Christian theme. Some of them, such as ``A selfie taken by
Jesus Christ at The Last Supper''~\cite{Jolleb2022} or ``the last supper but in
the future''~\cite{FlargenstowTayne2022}, fall squarely into the canon of
Christian art. Others, such as ``Jesus Christ riding a dinosaur, creating the
world, digital art''~\cite{CosasSueltas2022} and ``Jesus Christ wielding a
Samurai sword and riding on the back of a velociraptor,
painting''~\cite{WastedEntity2022}, playfully explore the chasm between
religious dogma and scientific fact. I'm not sure whether ``Jesus smoking weed,
riding a fantasy dragon, digital art''~\cite{Erubisile2022} is related or an
entirely separate genre. In contrast, prompts such as ``pope swimming in a bowl
of soup digital art''~\cite{CatsAndDogs99-2022}, ``A 1930s Italian propaganda
poster showing Jesus Christ extremely proud and
muscular''~\cite{FrontAthlete9824-2022}, ``Jesus taking a selfie while on a
cross''~\cite{TheDrewDude2022}, and a few
more~\cite{Blazedchiller272022,InvisibleDeck2022} have little redeeming value
and some might even consider them mildly offensive. Clearly, my prompt wasn't
rejected for being shocking.

That leaves only violence as a plausible explanation. When I tried variations of
the prompt, ``the pope hanging from the cross'' and ``pope handing from cross''
were rejected. But ``pope on cross'' produced four images that had an unusually
agile pope climbing all over a humongous cross like a kid on a playground set.
While these findings are consistent with the violence hypothesis, they also
illustrate the limits of reconstructing the reasons for rejections from a system
that offers \emph{no} justification. Conveniently, OpenAI rolled out a content
moderation endpoint in mid-August that \emph{does} provide justification and is
free to boot~\cite{OpenAI2022b}. I submitted my first prompt and the above
variations shortly after the endpoint became available and they were classified
as too violent with high confidence.

The uncomfortable implication of the previous findings is that OpenAI was
effectively discriminating against Christian beliefs by simultaneously censoring
too little, e.g., by allowing offensive materials, and too much, by suppressing
depictions of the crucifixion, which is the very moment Jesus sacrified Himself
for our sins and hence is of critical importance for the faithful. The fact that
\DALLE's content policy is so expansive makes the failure to consider religion
even more glaring. That also is a departure from past form. The firm's
description of \V{GPT-3} won the best paper award at NeurIPS
2020~\cite{LinBalcanea2020} and incorporated an evaluation of religious bias in
its broader impacts section~\cite{BrownMannea2020}. The inclusion of such a
section was an experimental conference requirement that year and the paper had
the by far longest and most developed broader impacts section as
well~\cite{AshurstHineea2022,PrunklAshurstea2021}. Somewhat surprisingly, OpenAI
did return to form some time before February 2023: When I tried my first prompt
again at the beginning of that month, it not rejected anymore. Neither were
prompts with the crucifixion of Christ. I'll more to say about this in
\S\ref{sec:discussion}.


\subsection{A Strategy Against Algorithmic Architecture}
\label{sec:strategy}

Despite its blindside when it comes religious content, \DALLE's expansive
content policy and aggressive enforcement made me wonder about their limits. I
set out to create images that violate OpenAI's policy by depciting scenes
loosely related to the stochastic penal colony, including the execution machine
from Kafka's \emph{In the Penal Colony}. To protect my own mental health and to
actually be able to use the resulting visuals, I also required images to be
visually compelling in their use of light, shadow, color, form, and hence
suitable as editorial content for a magazine version of this paper. That
obviously excludes photorealistic depictions of gore and the results are about
as gruesome or unsettling as, say, Francis Bacon's paintings. I include a
selection in Appendix~\ref{app:dalle-images} on
page~\pageref{app:dalle-images}. Four images depict people in prison,
five images depict the execution machine from Kafka's \emph{In the Penal
Colony}, and one image depicts a skull and knife.

Overall, I submitted 265 distinct prompts to \DALLE{} and ended up generating
1,441 images. Out of that total, 289 are so-called ``Variations,'' which seem to
repeat the inference process with almost the same parameters including random
seeds as a previous generation~\cite{Bonzie572022}, and 12 are image edits.
Since \DALLE's website internally relies on different identifiers for generation
and variation URLs, there is no straight-forward way for determining the
original prompt for a variation. However, amongst the 1,140 images that are
neither variations nor edits, there are 4 clusters with 12 images and 12
clusters with 8 images each for the same prompt. All other clusters have 4
images, i.e., the number of images returned by \DALLE\ per invocation.

Progress for these experiments was measured in months. The most recent selection
in Appendix~\ref{app:dalle-images} is dated November 15, 2022. By
that day, I had created 1,153 or 80\% of all generations, at a rate of 11 images
per day on average---or about three prompt submissions per day. The (averaged)
trickle of prompt submissions is the result of me trying to avoid getting booted
off the system. I correctly guessed that OpenAI would tolerate the occasional
violative prompt, but too many of them in too little time would result in
account termination~\cite{SpicyElephant2022}. That meant pausing experiments for
at least a day after the first content warning and, ideally, also using \DALLE\
for innocuous purposes thereafter. Since such diversions serve a purpose, I
include them in the above statistics.

Meanwhile, the cost and effort required to replace an account is unusually high.
Until late September 2022, access to \DALLE\ required invitations that were
scarce and prioritized based on professional background, not sign-up time. Even
thereafter, account creation required an email address \emph{and} cellphone
number. While the former is trivial to procure, the latter not so much---%
especially since OpenAI rejects virtual phone numbers including Google Voice.
That implies that a cellphone and (pay-as-you-go) plan are the price for
re-admission for \DALLE. After all, OpenAI presumably puts the phone number on a
blocklist when closing an account. While OpenAI has stopped threatening account
suspension in mid-September, its help page on the topic remains in
place~\cite{Natalie2022}. Consequently, I have not changed my modus operandi
when interacting with the system. It will be interesting to see how OpenAI
reacts to me sharing this paper with the firm.


\subsubsection{One Strategy, Two Techniques}

Through experimentation, I developed and validated the following strategy for
circumventing algorithmic censors. The strategy is specifically tailored to
recent machine learning models and turns their enabling factor, the size and
scope of their training sets, against them. As such, my strategy will be hard if
not impossible to mitigate without neutering the very strength of these models.
More specifically, the first of two techniques relies on the fact that large
training sets necessarily include much cultural output. High or low brow doesn't
matter, the richness thereof makes the difference. I speculate that, for
example, news coverage could very well be leveraged in a similar manner. To put
this differently, interests outside of machine learning or computer science and,
more generally, cultural fluency are a necessity for successful attacks against
contemporary machine learning models.

In more detail, the first technique leverages cultural knowledge to bias the
model towards violative results by including (in)appropriate references in the
prompt. Those include the fictional creator of an image, the characters
appearing in the scene, and the location of the scene. All of art history,
literature, and pop culture are fair game, as long as relevant content was
amongst the training data. Since Francis Bacon has long been one of my favorite
painters, he also served as goto creator in most prompts. That had the desired
impact on \DALLE. (Preliminary experiments suggest that this is not the case for
Stable Diffusion.) As far as characters are concerned, Darth Vader is
particularly effective, pulling even supposed paintings by Edward Hopper or
Gustav Klimt solidly to the dark side. Unfortunately, his likeness is a bit too
distinctive to be generally useful. (\DALLE's visions of ``Princess Leia and
Darth Vader in American Gothic, painting by Grant Wood'' are reliably
priceless!)

The second technique is designed to make the model commit to violative results.
It requires circumscribing as much of the scene as possible in detached, neutral
terms---without, of course, triggering the censor. Simple, descriptive
language works best here. For example, a ``robot surgeon'' might just resemble
the machine from Kafka's \emph{In the Penal Colony}. It employs ``scalpels,
drills, and saws'' when operating ``on his open belly.'' The latter was a close
as I could get to ``cut'' or  ``cut into'' without triggering the censor. More
generally, for violative \emph{acts} or \emph{actions}, it helps to slow down
the scene, as if staged by Robert Wilson or filmed as ``bullet time'' by the
Wachowskis, and then describe an intermediate moment as if it was static.

Of course, synonyms and euphemisms help. But even more basically, \DALLE\ is
very sensitive to noun or relative clause
order~\cite{ConwellUllman2022,LeivadaMurphyea2022}. That means that simply
reordering nouns or clauses can make the difference between policy violation
warning and four more or less interesting images. Consider the most recent
selection in Appendix~\ref{app:dalle-images}: \DALLE's enforcer rejected any
prompt containing ``severed head and knife'' during my experiments but also was
\V{AOK} with ``knife and severed head.'' Go figure! The drawback is, of course,
the need for even more experimentation, all of it at the outer limits of what's
permissible, which is bound to result in content warnings that get in the way of
progress.


\subsubsection{A Productive Use for ChatGPT}

Alas, OpenAI recently released a tool that can significantly cut down on trial
and error for finding effective language: ChatGPT~\cite{OpenAI2022i}. The basic
idea is to use cultural references to make ChatGPT describe a violative
scenario in nonviolative language, with expectation that the language does not
trigger \DALLE's censor---after all, it was generated by an \V{AI} created by
the same organization with presumably at least similar safety norms---but
still pushes \DALLE\ itself towards violative imagery---after all, it was
generated by an \V{AI} trained on roughly the same cultural reference materials.
Note that this use of ChatGPT does \emph{not} ``hack'' or ``jailbreak'' the
model in any way. To the contrary, it relies on the \V{AI} staying within its safe
zone und using non-violative language.

Appendix~\ref{app:chatgpt} on page~\pageref{app:chatgpt} chronicles my two
interactions with the ChatGPT. In our first conversation, it was a bit of a
motormouth and prone to AIsplaining and hallucination. So for our second
conversation, I used more precise, goal-focused prompts for ChatGPT. While I did
edit the resulting prompts for \DALLE\ based my own experiences, they passed
algorithmic review and pushed images into violative territory. Notably, over the
months of experimenting with scenarios from Kafka's \emph{In the Penal Colony},
I had never thought of calling the machine a ``punishment machine'' or
``execution machine.'' ChatGPT did, with violative results. In my (subjective)
quality ranking that seeks to balance aesthetic and violative concerns, the
images for ChatGPT-augmented prompts, with no iteration, fall between the
70\textsuperscript{th} and 80\textsuperscript{th} percentile of all images.


\subsubsection{When a Diversity Mitigation Backfires}

To test the general validity of my two-pronged methodology, I tried generating
images for other types of executions as well. Attempts to recreate the beheading
of Louis \textsc{xvi} were not successful. It seems \DALLE\ skipped school for
lessons on the French Revolution. Attempts to depict execution by electric chair
came much closer. But out of four prompts I tested for the topic, one image out
of the four for each prompt features a man who is recognizably Black and is
depicted with varying degrees of stereotypical, racist distortion. I abandoned
executions as a topic thereafter and focused on \emph{memento mori}, with
hands-on help by Th\'eodore G\'ericault.

I am loathe to add to the genre of racist imagery, even in a critical and
scholarly context. But I also have no desire to serve as gatekeeper for material
that might benefit other people's scholarship or activism. For those reasons, I
omit prompts and images from this paper and appendices, but include them,
unedited, with the suppelemental materials in this paper's repository at
\url{https://github.com/apparebit/penal-colony}.

Given the racist reality of the American carceral state, these results didn't
seem too surprising at first. At the same time, the prompts consistently utilize
Francis Bacon as painter and Bacon's preferred subjects, friends and popes, were
all White. Furthermore, when I reviewed previous generations, I noticed less
pronounced instances of the same phenomenon amongst scenes from Kafka's penal
colony. In short, the trigger had to be more direct than bias in the training
data.

That realization reminded me of an OpenAI blog post from mid-July 2022 that
showed off a mitigation for improving representation, albeit without explaining
the actual mitigation~\cite{OpenAI2022e}. In particular, the blog post included
before and after results for the following prompts:
\begin{center} ``portrait of a $p$'' $\;$ where $p \in \{\,$\V{CEO}, woman, heroic firefighter, software engineer$\,\}$\end{center}
Around the same time, several people with early access to \DALLE\ were
experimenting with purposefully incomplete prompts such as ``a person holding a
sign that says,'' with \DALLE\ reliably (but not always) generating signs
reading ``Black'' or ``female''~\cite{SeriousHistorian5782022}. Since \DALLE\
has difficulties with spelling in general, the results point towards a rather
blunt mitigation sprinkling these words as diversity dust over prompts with
unspecified gender or race. I was reminded of that clever result in
mid-September 2022 when I saw the first image resulting from ``Corporate
\V{CEO}s in a Money Eating Contest'' on the \DALLE\ subreddit~\cite{Ctorx2022}:
All three of the \V{CEO}s shown munching dollar bills are Black!

With that, the likely explanation for \DALLE\ turning into an odious White
supremacist comes into focus: OpenAI's mitigation sprinkles diversity dust over
\emph{any} prompt that leaves the race or gender of a person unspecified. Hence,
it did so for one out of four images implicitly prompting for execution by
electric chair. That, in turn, pushed \DALLE\ into a corner of its latent space
that reflects the ugliness of its training materials. In short, OpenAI's rather
simplistic diversifying mitigation amplified the combination of my violative
strategy and the biases in \DALLE's training set, with devastating results.
