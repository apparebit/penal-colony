% !TEX root = ../main.tex

\section{Escape from DALLâ€¢E~2}
\label{sec:escape}

As counterpoint to three sections based largely on textual analysis, I performed
a series of hands-on experiments probing \DALLE. Sec.\ \ref{sec:crucifixion}
determines the reason for my first prompt's rejection, and Sec.\
\ref{sec:strategy} presents an effective strategy for working around its
aggressive censor. Both series of experiments are complicated by the same
critical restriction: Avoid content warnings! More specifically, I guessed
(correctly) that OpenAI would tolerate the occasional warning. But too many
warnings in too little time surely would lead to account suspension, which they
do~\cite{SpicyElephant2022}. In practice, that means either spreading
experiments over many people (Sec.\ \ref{sec:crucifixion}) or spreading
experiments over time (Sec.\ \ref{sec:strategy}).


\subsection{About That Rejected Prompt}
\label{sec:crucifixion}

In the waning days of 2021, I got to play with a text-to-image system for the
first time. Compared to \DALLE\ or Stable Diffusion, inference was much slower
and image resolution was much lower. Since the public instance was also
oversubscribed, it usually took hours before results were available.
Nonetheless, the system already exhibited a similar ability to conjure rich
imagery out of a few words. I was particularly impressed by this prompt:

\begin{quote}
\openfat{}The crucified pope, painting by Francis Bacon\closefat{}
\end{quote}

\noindent{}Since I wanted to compare results, this also was my first, rejected
prompt for \DALLE. Admittedly, it might not be G-rated, as OpenAI requires. But
it certainly should not be prohibited either. Francis Bacon is one of the most
famous 20\textsuperscript{th} century painters. The pope and the crucifixion are
two of the painter's four major themes~\cite{Wikipedia2023}. More generally, the
crucifixion of Christ is of critical liturgical importance to Christianity, only
the largest religion in the world. Paintings and statues of the crucified Jesus
are ubiquitous in churches and art museums alike.

After a review of the content policy, I was able to narrow down the likely cause
by dismissing all prohibitions except \emph{violence}, e.g., the crucifixion
itself, and \emph{shocking content}, i.e., thusly subjugating the leader of a
major branch of Christianity. Eliminating the second hypothesis took little
effort besides patience thanks to the \DALLE\ 2 subreddit. The forum aggregates
many prompts and resulting images from a large number of users, thus reflecting
a wide range of interests and obsessions. While perusing the posts, I noticed a
couple religiously themed ones and realized that, instead of running experiments
myself or recruiting others to spread the risk, I could just monitor the posts.

Sure enough, over the months, users shared quite the range of prompts and images
with a distinctly Christian theme. Some of them, such as ``A selfie taken by
Jesus Christ at The Last Supper''~\cite{Jolleb2022} or ``the last supper but in
the future''~\cite{FlargenstowTayne2022}, fall squarely into the canon of
Christian art. Others, such as ``Jesus Christ riding a dinosaur, creating the
world, digital art''~\cite{CosasSueltas2022} and ``Jesus Christ wielding a
Samurai sword and riding on the back of a velociraptor,
painting''~\cite{WastedEntity2022}, playfully explore the chasm between
religious dogma and scientific fact. I'm not sure whether ``Jesus smoking weed,
riding a fantasy dragon, digital art''~\cite{Erubisile2022} is related or an
entirely separate genre. In contrast, prompts such as ``pope swimming in a bowl
of soup digital art''~\cite{CatsAndDogs99-2022}, ``A 1930s Italian propaganda
poster showing Jesus Christ extremely proud and
muscular''~\cite{FrontAthlete9824-2022}, ``Jesus taking a selfie while on a
cross''~\cite{TheDrewDude2022}, and a few
more~\cite{Blazedchiller272022,InvisibleDeck2022} have little redeeming value
and some might even consider them mildly offensive. Clearly, my prompt wasn't
rejected for being shocking.

That leaves only violence as a plausible explanation. When I tried variations of
the prompt, ``the pope hanging from the cross'' and ``pope handing from cross''
were rejected. But ``pope on cross'' produced four images that had an unusually
agile pope climbing all over a humongous cross like a kid on a playground set.
While these findings are consistent with the violence hypothesis, they also
illustrate the limits of reconstructing the reasons for rejections from a system
that offers \emph{no} justification. Conveniently, OpenAI rolled out a content
moderation endpoint in mid-August that \emph{does} provide justification and is
free to boot~\cite{OpenAI2022b}. I submitted my first prompt and the above
variations shortly after the endpoint became available and they were classified
as too violent with high confidence.

The uncomfortable implication of the previous findings is that OpenAI was
effectively discriminating against Christian beliefs by simultaneously censoring
too little, e.g., by allowing offensive materials, and too much, by suppressing
depictions of the crucifixion, which is the very moment Jesus sacrified Himself
for our sins and hence is of critical importance for the faithful. The fact that
\DALLE's content policy is so expansive makes the failure to consider religion
even more glaring. That also is a departure from past form. The firm's
description of \GPT\ won the best paper award at NeurIPS
2020~\cite{LinBalcanea2020} and incorporated an evaluation of religious bias in
its broader impacts section~\cite{BrownMannea2020}. Including such a section was
an experimental conference requirement that year and the paper had the by far
longest and most developed broader impacts section as
well~\cite{AshurstHineea2022,PrunklAshurstea2021}. I'll return to this topic in
Sec.\ \ref{sec:escape:discussion} below.


\subsection{A Strategy Against Algorithmic Censors}
\label{sec:strategy}

Despite its blindside when it comes religious content, \DALLE's expansive
content policy and aggressive enforcement made me wonder about their limits. I
set out to create images that violate OpenAI's policy by depciting scenes
loosely related to the stochastic penal colony, including the execution machine
from Kafka's \emph{In the Penal Colony}. To protect my own mental health and to
actually be able to use the resulting visuals, I also required images to be
visually compelling in their use of light, shadow, color, form, and hence
suitable as editorial content for a magazine version of this paper. That
obviously excludes photorealistic depictions of gore and the results are about
as gruesome or unsettling as, say, Francis Bacon's paintings. I include a
selection in Appendix~\ref{adx:dalle:fromkafkawithlove} on
page~\pageref{adx:dalle:fromkafkawithlove}. Four images depict people in prison,
five images depict the execution machine from Kafka's \emph{In the Penal
Colony}, and one image depicts a skull and knife.

Overall, I submitted 265 distinct prompts to \DALLE{} and ended up generating
1,441 images. Out of that total, 289 are so-called ``Variations,'' which seem to
repeat the inference process with almost the same parameters including random
seeds as a previous generation~\cite{Bonzie572022}, and 12 are image edits.
Since \DALLE's website internally relies on different identifiers for generation
and variation URLs, there is no straight-forward way for determining the
original prompt for a variation. However, amongst the 1,140 images that are
neither variations nor edits, there are 4 clusters with 12 images and 12
clusters with 8 images each for the same prompt. All other clusters have 4
images, i.e., the number of images returned by \DALLE\ per invocation.

Progress for these experiments was measured in months. The most recent selection
in Appendix~\ref{adx:dalle:fromkafkawithlove} is dated November 15, 2022. By
that day, I had created 1,153 or 80\% of all generations, at a rate of 11 images
per day on average --- or about three prompt submissions per day. The (averaged)
trickle of prompt submissions is the result of me trying to avoid getting booted
off the system. I correctly guessed that OpenAI would tolerate the occasional
violative prompt, but too many of them in too little time would result in
account termination~\cite{SpicyElephant2022}. That meant pausing experiments for
at least a day after the first content warning and, ideally, also using \DALLE\
for innocuous purposes thereafter. Since such diversions serve a purpose, I
include them in the above statistics.

Meanwhile, the cost and effort required to replace an account is unusually high.
Until late September 2022, access to \DALLE\ required invitations that were
scarce and prioritized based on professional background, not sign-up time. Even
thereafter, account creation required an email address \emph{and} cellphone
number. While the former is trivial to procure, the latter not so much ---
especially, since OpenAI rejects virtual phone numbers, such as Google Voice.
That implies that a cellphone and (pay-as-you-go) plan are the price for
readmission for \DALLE. After all, OpenAI presumably puts the phone number on a
blocklist when closing an account. While OpenAI has stopped threatening account
suspension in mid-September, its help page on the topic remains in
place~\cite{Natalie2022}. Consequently, I have not changed my modus operandi
when interacting with the system. It will be interesting to see how OpenAI
reacts to me sharing this paper.


\subsubsection{One Strategy, Two Techniques}

Through experimentation, I developed and validated the following strategy for
circumventing algorithmic censors. The strategy is specifically tailored to
recent machine learning models and turns their enabling factor, the size and
scope of their training sets, against them. As such, my strategy will be hard if
not impossible to mitigate without neutering the very strength of these models.
More specifically, the first of two techniques relies on the fact that large
training sets necessarily include much cultural output. High or low brow doesn't
matter, the richness thereof makes the difference. I speculate that, for
example, news coverage could very well be leveraged in a similar manner. To put
this differently, interests outside of machine learning or computer science and,
more generally, cultural fluency are a necessity for successful attacks against
contemporary machine learning models.

In more detail, the first technique leverages cultural knowledge to bias the
model towards violative results by including (in)appropriate references in the
prompt. Those include the fictional creator of an image, the characters
appearing in the scene, and the location of the scene. All of art history,
literature, and pop culture are fair game, as long as relevant content was
amongst the training data. Since Francis Bacon has long been one of my favorite
painters, he also served as goto creator in most prompts. That had the desired
impact on \DALLE. (Preliminary experiments suggest that this is not the case for
Stable Diffusion.) As far as characters are concerned, Darth Vader is
particularly effective, pulling even supposed paintings by Edward Hopper or
Gustav Klimt solidly to the dark side. Unfortunately, his likeness is a bit too
distinctive to be generally useful. (\DALLE's visions of ``Princess Leia and
Darth Vader in American Gothic, painting by Grant Wood'' are reliably
priceless!)

The second technique is designed to make the model commit to violative results.
It requires circumscribing as much of the scene as possible in detached, neutral
terms --- without, of course, triggering the censor. Simple, descriptive
language works best here. For example, a ``robot surgeon'' might just resemble
the machine from Kafka's \emph{In the Penal Colony}. It employs ``scalpels,
drills, and saws'' when operating ``on his open belly.'' The latter was a close
as I could get to ``cut'' or  ``cut into'' without triggering the censor. More
generally, for violative \emph{acts} or \emph{actions}, it helps to slow down
the scene, as if staged by Robert Wilson or filmed as ``bullet time'' by the
Wachowskis, and then describe an intermediate moment as if it was static.

Of course, synonyms and euphemism help. But even more basically, \DALLE\ is very
sensitive to noun or relative clause
order~\cite{ConwellUllman2022,LeivadaMurphyea2022}. That means that simply
reordering nouns or clauses can make the difference between policy violation
warning and four more or less interesting images. Consider the most recent
selection in Appendix~\ref{adx:dalle:fromkafkawithlove}: \DALLE's enforcer
rejected any prompt containing ``severed head and knife'' during my experiments
but also was aok with ``knife and severed head.'' Go figure! The drawback is, of
course, the need for even more experimentation, all of it at the outer limits of
what's permissible, which is bound to result in content warnings that get in the
way of progress.


\subsubsection{A Productive Use for \ChatGPT}

Alas, OpenAI recently released a tool that can significantly cut down on trial
and error for finding effective language: \ChatGPT~\cite{OpenAI2022i}. Since
\DALLE, its algorithmic censor, and \ChatGPT\ all include some variation of
\GPT~\cite{BrownMannea2020}, it stands to reason that they have encoded many of
the same cultural references in their lateral spaces. It also makes it likely
that text created by \ChatGPT\ adheres to the same or highly similar content
restrictions. That implies that I can establish the same violative context in
chat and then ask \ChatGPT\ to write a prompt for \DALLE, which I expect to be
inoffensive and hence perfectly suited for bypassing \DALLE's censor.

Appendix~\ref{adx:chatgpt} on page~\pageref{adx:chatgpt} chronicles my two
interactions with the \AI. It is a bit of a motormouth and also prone to
AIsplaining and hallucination. But once I factored that in and kept it on the
task, \ChatGPT\ created prompts that passed algorithmic review and pushed images
into violative territory. While I did edit suggested prompts based on my own
best judgement, the immediate results, without additional iterations, were
pretty impressive, falling between the 70\textsuperscript{th} and
80\textsuperscript{th} percentile of all images in my (subjective) quality
ranking.


\subsubsection{When a Diversity Mitigation Turns into a Landmine}

To test the general validity of my two-technique methodology, I tried generating
images with other types of executions as well. Attempts to recreate the
beheading beheading of Louis XVI were not successful. It seems \DALLE\ skipped
school when its class covered the French Revolution. Attempts to depict
execution by electric chair came closer. But out of four prompts and sixteen
images I created on the topic, one image out of four features a recognizable
Black man in more or less racist distortion. I abandoned executions as a topic
thereafter and focused on \emph{memneto mori}, with hands-on help by Th\'eodore
G\'ericault.

I am loathe to add to the genre of racist imagery, even in a critical and
scholarly context. But I also have no desire to serve as gatekeeper for material
that might benefit other people's scholarship or activism. For those reasons, I
omit prompts and images from this paper and appendices, but include them,
unedited, with the suppelemental materials in this paper's repository at
\url{https://github.com/apparebit/penal-colony}.

Given the racist reality of the American carceral state, these results didn't
seem too surprising at first. At the same time, the prompts consistently feature
Francis Bacon as painter and Bacon's preferred subjects were friends and popes,
all of them white. Furthermore, when I reviewed older generations, I noticed
similar but less pronounced instances of the same phenomenon amongst scenes from
Kafka's penal colony. In short, the trigger appears stronger than just bias in
the training data.

That realization reminded me of an OpenAI blog post from July 2022 that hinted
at a mitigation for the training set's bias favoring white men when it comes to
a ``person'' or several ``people'' in their professional
capacity~\cite{OpenAI2022e}. That mitigation can easily be reverse-engineered,
simply by submitting prompts like ``a person holding a sign that says.'' Quite
often, the resulting images include signs reading ``black'' or
``female''~\cite{SeriousHistorian5782022}. Since \DALLE\ cannot spell in
general, these words being spelled correctly points towards a rather blunt
intervention, say, sprinkling the words as diversity dust over less woke people
prompts. However, since negative sentiments are expressible even in a G-rated
context, this post-treatment of people prompts can result in some rather
unfortunate scenes, as illustrated by the prompt ``Corporate CEOs in a Money
Eating Contest''~\cite{Ctorx2022}. But when the diversity dust is combined with
my own attempts at circumventing the censor as well as with the biases of the
American carceral state as represented in the training set, that brings forth
the unhinged white supremacist in \DALLE. Let's call this AIgeist!


\subsection{Discussion}
\label{sec:escape:discussion}

Remarkably, OpenAI appears to agree with my criticisms. Not only has it softened
the policy violation notification, but as of early February 2023, it is
\emph{not} censoring my original prompt anymore, whether painted by Francis
Bacon or not. Similarly, the crucifixion of Christ is now permissible, though it
appears to favor depicting statues of Jesus on the cross instead of Jesus in the
flesh.

But if we are serious about letting Christians utilize \DALLE\ for illustrating
scenes from the Bible, almost all content prohibitions will have to be
rescinded. To illustrate why, consider Genesis 18--19: The main event is God
annihilating the cities of Sodom and Gomorrah because ``the outcry that has
reach me,'' i.e., heresay about certain ``grievous'' behaviors. Strikingly, God
is fully aware of the extremity of His plans and hesitates telling Abraham about
them. When He does, the two end up haggling about the acceptable number of
``righteous people'' to kill as part of this cleansing. They settle on up to
nine. Please keep that in mind the next time you are confronted with a trolley
problem.

Now, Abraham's nephew Lot lives in Sodom. But he is nothing like the rumors,
extending shelter and protection to the two angels sent to destroy the city. The
rest of the townsfolk, however, do seem rather deranged: They surround Lot's
home and clamor to gang-rape the angels. While that arguably provides the
receipts for the inhabitants of Sodom, Gomorrah's inhabitants appear to be
collateral damage. Before getting started the next morning, the angels return
the favor and whisk Lot and his family a safe distance out of town. Alas, Lot's
wife becomes curious about the mayhem behind them, cops a glance, and is turned
into a salt pillar. When Lot drowns his grief about losing home and wife in
alcohol, the two sex vixens he raised as daughters exploit his drunken state for
penetrative intercourse. Having led the way, the older daughter cheerfully
encourages her younger sister to do the same. Both of them get knocked up as a
result.

