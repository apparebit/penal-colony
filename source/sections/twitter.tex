\section{Tweet-Da-F\'e}
\label{sec:tweet-da-fe}

Early one morning in October 2021, I had just finished reading an article about
some oil industry association spending millions of dollars on lobbying and
advertising to derail the Biden administration's push for climate change
legislation~\cite{Tabuchi2021}. Additionally, three of the association's larger
member companies spent millions of dollars each towards that same goal---%
despite also being responsible for 8.7\% of all global CO$_2$ emissions since
1965~\cite{TaylorWatts2019}.

I was enraged. To vent, I composed a caustic tweet that @-mentioned the three
firms and stated that I was looking forward to their \CEO{}s facing capital
punishment for genocide. I was aware of the statement's severity and hence
incivility while writing the tweet. But I told myself that it was ok, since the
statement implies a formal, legal process that still is practiced in the United
States. I even included that argument in both of my appeals.

I remain somewhat ambivalent about the tweet. When ExxonMobil's internal
projections from 1977 to 2003 ``accurately forecast warming that is consistent
with subsequent observations''~\cite{SupranRahmstorf2023}, when birds fall dead
from the skies~\cite{Dave2022}, 11 billion crabs just
vanish~\cite{Olmstead2022}, and a third of Pakistan floods~\cite{Chughtai2022}
because of that warmining, it is hard \emph{not} to wish harm on major oil
companies and their \CEO{}s. Yet, the record-setting execution spree towards the
end of Donald Trump's
presidency~\cite{Arnsdorf2020,Kovarsky2022,SuebsaengReis2023} also makes clear
that the content of the tweet isn't just utterly incompatible with this paper's
basic premise, but tweet and oil company greed share the same basic inhumanity.
It appears then that I acted, more or less, as a \emph{daily active shithead}
that morning~\cite{Sherman2021}.

In either case, Twitter's \AI\ was not impressed by the tweet's incivility.
Within a couple of seconds after posting at most, it removed the tweet and
locked my account. Compared to the content warning for \DALLE, the stated
justification was far more specific:

\begin{quote}
\openfat\textbf{Violating our rules against
\href{https://web.archive.org/web/20220905021323/https://help.twitter.com/en/rules-and-policies/abusive-behavior}{abuse
and harassment}.}

You may not engage in the targeted harassment of someone, or incite other people
to do so. This includes wishing or hoping that someone experiences physical
harm.\closefat{}
\end{quote}

\noindent{}The linked policy on abusive behavior, reproduced in
Appendix~\ref{app:twitter-abusive-behavior} on
page~\pageref{app:twitter-abusive-behavior}, is not only specific but genuinely
helpful. It is written in accessible, well-structured prose: The policy starts
with its rationale, is followed by the different kinds of abusive content, and
concludes with a range of possible sanctions. The mid-section on kinds of
abusive content features well-delineated and reasonable prohibitions. It even
reassures readers that the firm is well aware that some tweets, by themselves,
may appear to violate the policy but, when considered in their original context,
do not.

Thanks to the effective presentation, finding the concrete prohibition
applicable to my tweet was easy: ``Wishing, hoping, or calling for serious harm
on a person or group of people.'' After elaborating on possible context and
giving examples, the policy---rather reasonably---allows that some wishes of
harm may be justified, in the heat of the moment, as expressions of outrage. In
such cases, Twitter still requires offending tweets to be deleted but does not
impose penalties. Apparently, rapists and child abusers count as legitimate
targets under this exception, but oil company \CEO{}s do not---yet.

I appealed the decision by Twitter's AI that same morning. Or at least, I tried
to: Twitter's form for filing an appeal seems to have the same character limit
as a tweet. That excludes most arguments besides a succinctly stated single
reason. Alas, my justification was far from that and, not surprisingly, Twitter
rejected the appeal three days later. However, the form email notifying me of
the rejection wasn't even filled in, despite containing instructions in \HTML\
comments. Since I had located another page for launching an appeal that wasn't
marred by the original form's character limit, I tried again with that form,
this time focusing mostly on the bad form. When that second appeal went
unanswered for three weeks, I gave up. I withdrew my appeal, acknowledged that I
``violated the Twitter Rules,'' and deleted the offending tweet---all with one
click on the red ``Delete'' button.

Alas, residual effects from the episode remain. When I try to sign up to Twitter
for Professionals, I get a notification that ``something's missing,'' even
though my account meets all criteria stated in Twitter's documentation. Yet a
satirical account of mine, which I opened more recently and which describes my
alter ego as a ``lifelong practitioner of faggotry, promoter of the gay agenda,
and unrepentant socialist monarchist,'' could sign up to Twitter for
Professionals within days of account creation.


\subsection{A Punishing Performance}

With OpenAI's policy enforcement being consistently Kafkaesque, its impact is
equivalent to \lingchi, death by a thousand cuts, via the algorithm's Harrow.
That may be excessive, but it also is consistent and hence at least
\emph{appears} credible. In contrast, Twitter's enforcement has very little to
do with its eminently reasonable policy beyond selecting candidate users, or
Condemned, for the firm's personalized performance of punishment.

As illustrated in Appendix~\ref{app:twitter-staging} on
page~\pageref{app:twitter-staging} the set design is rather crude: The
violative tweet is featured prominently on screen and demarcates the extent of
the Condemned's Twitter for the duration of this performance. While Twitter
originally claimed that, ``while in this state, you can still browse Twitter,
but you're limited to only sending Direct Messages to your followers---no
Tweets, Retweets, Fleets, follows, or likes,'' that's plain false. The
Condemned's Twitter brooks no other content or interaction.

While the set design lacks subtlety, it is quite effective: It reminds the
audience of (1) the final arbiter of account access (or lack thereof) being
Twitter---and Twitter only, (2) the very transgression that started and
apparently justifies this performance, and (3) the one approved way out of one
tweet limbo: Admit the violative character of the tweet and then delete the
tweet. The set design also is surprisingly versatile. By having a well-defined
visual and expressive center, incidental text and button surrounding the one
tweet that no one else can see may change without distracting from the overall
message. Hence, after clicking ``cancel your appeal,'' the text below the one
tweet turns into an acknowledgement of guilt combined with a button to
``Delete'' that last vestige of violative content.

In this context, calling that digital artifact a ``tweet'' and having the
Condemned ``delete'' it is largely farcical---and also coercive, punitive, and
somewhat degrading, which makes for four Kafkaesque co-factors. That may just be
a major factor in explaining why many Twitter users in one study about
procedural justice emphasized dignity and respect~\cite{KatsarosTylerea2022},
qualities Twitter does not extend to the Condemned. That the artifact has
already been deleted from the social network by the one entity that has total
control over what content gets posted, Twitter itself, only underlines this
corrosive attitude. That also makes the starring role of the artifact in a
particular punishing performance the likely last hurrah before cancellation.

Unusually for such an elaborate staging, the audience is just the Condemned.
Apparently, mechanization of content review via \AI\ makes it cost-effective to
nano-target the performance to just one user. To keep things interesting, the
audience is also forced to participate as (sole) cast and makes one substantive
choice: They determine the duration of the performance, hours if they forgo an
appeal, days if they appeal, or forever if they walk away. Alas, my use of the
word ``appeal'' reflects Twitter's practice and hence is of uncertain
significance in the real world. After all, when Twitter limits justifications to
280 characters, keeps admonishing the Condemned that ``you won't be able to
access your Twitter account'' and to ``just delete your content,'' provides no
explanation when rejecting an appeal, and discloses no statistics on appeals in
its yearly transparency reports (more on that in \S\ref{sec:census}), the word
appeal just doesn't have its usual meaning.

Taken together, the particulars of the punishing performance combine into an
intervention that reminds of Catholic
Inquisition~\cite{Lea1906a,Lea1906b,Lea1906c,Lea1906d} or Maoist denunciation
rallies~\cite{Yang2021} more than a governance function. Amazingly, the
\AI-based personalization of the performance also avoids all the power-eroding
downsides identified by Foucault. From a humanitarian viewpoint, Twitter's
performance also avoids the violence and torture pervasive amongst its
historical precedents. But that may just be because emotional abuse is the only
possible abuse given the electronic medium. A far more important factor in the
performance's longevity is that it such a targeted affair and hence the vast
majority of Twitter users will never experience it. If pressed, they can always
reassure themselves with Twitter's oh so reasonable policies, whereas any trace
of hurt or anger makes a Condemned come across as the opposite, that is,
positively unreasonable, if not hysterical---and hence so much easier to
dismiss and ignore.

Still, the lack of physical force and torture do raise the question of why
anyone would ever put up with that shit. The reason was pre-Musk Twitter's
rather unique position as breaking news service, political townsquare,
professional society, and corporate customer service platform in one. Thanks to
that combination, the threat of account termination was substantial and,
depending on a user's Twitter presence, could approach something like real-world
social death. However, thanks to Mr Musk's ``extremely hardcore'' leadership
since taking over the firm~\cite{SchifferNewtonea2023}, Twitter lost plenty of
users and advertisers. Worse, Mr Musk insists on not only running the social
network according to his ever-changing whims, but also must be the most visible
user, dominating notifications. Hence a return to old form seems impossible.


\subsection{Twitter's Neutrality and Trustworthiness}

The cognitive dissonance between Twitter's measured policy and its punishing,
performative enforcement raises questions about the culture enabling such
obviously divergent practices. I suspect that the very dehumanizing
condenscencion engendered in the punishing performance is the primary reason
because it made Twitter look like the good guys keeping daily active shitheads
in check. That dissonance is, of course, also deeply corrosive and raises
significant doubts about Twitter's trustworthiness and even integrity. It
doesn't help here that content policies, their enforcement, and their
transparency data are mostly silent on a critical salient feature: the use of
\AI. But that use is not new and dates back to the beginning of the pandemic at
the very least~\cite{ScottKayali2020}. In short, the firm had plenty of time to
update its documentation.

\begin{table}
\caption{Search terms and number of hits on Twitter's help pages (21 October, 2022)}
\label{table:search}
\begin{tabular}{lr}
\textbf{Search Term} & \textbf{Results} \B \\ \hline
AI & \T0 \\
algorithm & 5 \\
artificial intelligence & 1 \\
machine learning & 3 \\
\end{tabular}
\end{table}

Alas, that omission isn't limited to content policy etc, but extends to
\emph{all} of Twitter's help pages. Table~\ref{table:search} quantifies the
number of results from searching for common variations of the term ``\AI'' using
Twitter's own search functionality. The darth of relevant material is striking.
Not only were there hardly any mentions, but existing ones amounted to little
more than acknowledgements that, for instance, top tweets, topics, and
recommendations are curated algorithmically. There certainly were no
context-providing dataset, model, or system cards to be
found~\cite{GebruMorgensternea2021,MitchellWuea2019,ProcopeCheemaea2022}. So
much also for Twitter's stated commitment to implementing the Santa Clara
Principles, which require detailed disclosure of automated content
moderation~\cite{AccessNowACLUFoundationOfNorthernCaliforniaea2021}.

Twitter's transparency report nonetheless helps confirm an important aspect of
its automated content review, namely the exact timing. When my account was
blocked in October 2021, the notification thereof was nearly instantaneous after
posting, but I wasn't entirely sure whether Twitter's application had confirmed
the posting of my violative tweet. This matters since Twitter reviewing all
content before posting also eliminates any notion of human harm and hence the
justification for any form of punishment. I made that a major point in my
appeals. Alas, it appears that Twitter schedules posting and reviewing tasks in
parallel. In its reporting, Twitter uses the rather imprecise bands <100,
100--1,000, and >1,000~\cite{Twitter2021}. In contrast, Pinterest uses bands 0,
1--9, 10--100, and >100~\cite{Pinterest2022} and YouTube uses bands 0, 1--10,
and >100~\cite{Google2022}. Clearly, the latter two social media are confident
in their proactive content removal, whereas Twitter is not.

Note that user-initiated content review moves at a much slower pace. I reported
a tweet by a news organization that seemed to wish a fate not unlike the one I
had in mind for oil company \CEO{}s on the Parkland school shooter after his
sentencing to life in prison~\cite{ShapiroDeliso2022}. Twitter took about eight
hours to respond with a decision. Not surprisingly, the firm also rejected that
complaint. While another tweet would have made for a better equivalence, that
tweet was posted by a regular individual and reporting them seemed ethically
dubious.

Finally, Elon Musk's reign has resulted in further evidence that the Twitter of
yore was not trustworthy. Much of the reporting under the banner of ``Twitter
files,'' including most of Matt Taibbi's tweets, suffer from breathless
overclaims and hence are a bit hard to take. However, the Free Press'
investigation into secret blacklists, including for supposed Covid-19
misinformation that wasn't really misinformation, raise uncomfortable concerns
about heavyhanded over-moderation and a lack of transparency encouraging
abuse~\cite{WeissShrierea2022,Zweig2022}. Alas, the fact that Twitter's new head
of trust, Ella Irwin, is shown to casually use ``goddess mode,'' a special user
interface that enables her to impersonate \emph{any} user and post content under
their identity, does not reflect positively on Mr Musk's commitment to securing
the platform.
