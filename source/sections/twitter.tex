\section{Tweet-Da-F\'e}
\label{sec:tweet-da-fe}

Early one morning in October 2021, I had just finished reading an article about
some oil industry association spending millions of dollars on lobbying and
advertising to derail the Biden administration's push for climate change
legislation~\cite{Tabuchi2021}. Additionally, three of the association's larger
member companies spent millions of dollars each towards that same goal---%
despite also being responsible for 8.7\% of all global CO$_2$ emissions since
1965~\cite{TaylorWatts2019}. I was enraged. To vent, I composed a caustic tweet
that @-mentioned the three firms and stated that I was looking forward to their
\V{CEO}s facing capital punishment for genocide. I was well aware of the
statement's severity and incivility while writing it. But I told myself that
that was ok, since the statement implies a formal, legal process that is still
practiced in the United States. I even included that argument in both of my
appeals.

I remain ambivalent about the tweet. With ExxonMobil's internal projections from
1977 to 2003 ``accurately forecasting warming that is consistent with subsequent
observations''~\cite{SupranRahmstorf2023}, with birds falling dead from the
skies~\cite{Dave2022}, 11 billion crabs just vanishing~\cite{Olmstead2022}, and
a third of Pakistan flooding~\cite{Chughtai2022} because of climate change, it
is hard \emph{not} to wish harm on responsible parties including all oil
companies and their \V{CEO}s. Yet, the record-setting execution spree towards
the end of Donald Trump's
presidency~\cite{Arnsdorf2020,Kovarsky2022,SuebsaengReis2023} also makes clear
that the content of the tweet isn't just utterly incompatible with this paper's
basic premise, but that tweet and oil company greed share the same basic
inhumanity. It appears that I acted as a \emph{daily active shithead} that
morning~\cite{Sherman2021}.

The tweet's incivility certainly triggered Twitter's \V{AI}. Within a couple of
seconds after posting at most, it removed the tweet and locked my account.
Compared to the content warning for \DALLE, the stated justification was far
more specific:

\begin{quote}
\openfat\textbf{Violating our rules against
\href{https://web.archive.org/web/20220905021323/https://help.twitter.com/en/rules-and-policies/abusive-behavior}{abuse
and harassment}.}

You may not engage in the targeted harassment of someone, or incite other people
to do so. This includes wishing or hoping that someone experiences physical
harm.\closefat{}
\end{quote}

\noindent{}The linked policy on abusive behavior, reproduced in
Appendix~\ref{app:twitter-abusive-behavior} on
page~\pageref{app:twitter-abusive-behavior}, is not only specific but genuinely
helpful. It is written in accessible, well-structured prose: The policy starts
with a rationale, is followed by the different kinds of abusive content, and
concludes with a range of possible sanctions. The mid-section on kinds of
abusive content features well-delineated and reasonable prohibitions. It even
reassures readers that the firm is well aware that some tweets, by themselves,
may appear to violate the policy but, when considered in their original context,
do not.

Thanks to the effective presentation, finding the concrete prohibition
applicable to my tweet was easy: ``Wishing, hoping, or calling for serious harm
on a person or group of people.'' After elaborating on possible context and
giving examples, the policy---rather reasonably---allows that some wishes of
harm may be justified, in the heat of the moment, as expressions of outrage. In
such cases, Twitter still requires offending tweets to be deleted but does not
impose penalties. Apparently, rapists and child abusers count as legitimate
targets but oil company \V{CEO}s do not---yet.

I appealed the decision by Twitter's \V{AI} that same morning. Or at least, I
tried to: Twitter's form for filing an appeal seems to have the same character
limit as a tweet. That excludes most arguments besides a succinctly stated
single reason. Alas, my justification was far from that and, not surprisingly,
Twitter rejected the appeal three days later. However, the form email notifying
me of the rejection wasn't even filled in, despite containing instructions in
\V{HTML} comments. Since I had located another page for launching an appeal that
wasn't marred by the original form's character limit, I tried again with that
form, this time focusing mostly on the bad form. When that second appeal went
unanswered for three weeks, I gave up. I withdrew my appeal, acknowledged that I
``violated the Twitter Rules,'' and deleted the offending tweet---all with one
click on the red ``Delete'' button.

Alas, residual effects from the episode remain. When I try to sign up to Twitter
for Professionals, I get a notification that ``something's missing,'' even
though my account meets all criteria stated in Twitter's documentation.
Meanwhile, a satirical account of mine, which I opened more recently and which
describes my alter ego as a ``lifelong practitioner of faggotry, promoter of the
gay agenda, and unrepentant socialist monarchist,'' could sign up to Twitter for
Professionals within days of account creation.


\subsection{A Punishing Performance}

With OpenAI's policy enforcement being consistently Kafkaesque, its impact is
equivalent to \lingchi, death by a thousand cuts, via the algorithm's Harrow.
That may be excessive, but it also is consistent and hence at least
\emph{appears} credible. In contrast, Twitter's enforcement has very little to
do with its eminently reasonable policy beyond selecting candidate users, or
\emph{Condemned}, for the firm's personalized performance of punishment.

As illustrated in Appendix~\ref{app:twitter-staging} on
page~\pageref{app:twitter-staging} the set design is rather crude: The violative
tweet is featured prominently on screen and demarcates the extent of the
Condemned's Twitter for the duration of this performance. While Twitter's email
notifying me of the violation claimed that, ``while in this state, you can still
browse Twitter, but you're limited to only sending Direct Messages to your
followers---no Tweets, Retweets, Fleets, follows, or likes,'' that's plainly
false. The Condemned's Twitter brooks no other content or interaction.

While the set design lacks subtlety, it is quite effective. It reminds the
audience of the very transgression that started this performance. It reminds the
audience of the only certain way out of one tweet limbo---admitting the
violative character of the tweet and then deleting it. And it reminds the
audience of the final arbiter of account access (or lack thereof): Twitter and
Twitter only. The set design also is surprisingly versatile. By having a
well-defined visual and attentive center, incidental text and \V{UI} widgets
surrounding the one tweet that no one else can see may change without
distracting from the overall message. Hence, after clicking ``cancel your
appeal,'' the text below the one tweet that no one else can see turns into an
acknowledgement of guilt combined with a button to ``delete'' that last vestige
of violative content.

In this context, calling that digital artifact a ``tweet'' and having the
Condemned ``delete'' it is largely farcical---also coercive, punitive, and
somewhat degrading. After all, the tweet has long been purged from the platform
by the one entity that has total control over what content gets posted, Twitter.
In all likelihood, the tweet's current starring role isn't harbinger of future
popularity to come, but rather its last hurrah before permanent cancellation.
The farcical, coercive, punitive, and somewhat degrading character of the
performance makes for the four main Kafkaesque co-factors. It also makes for a
resounding lack of dignity and respect afforded to the Condemned by
Twitter---which may just explain the surprising emphasis on just those two
qualities exhibited by former Condemned in a recent survey on procedural justice
on Twitter (see \S5.5 in~\cite{KatsarosTylerea2022}).

The elaborate staging features one more twist: The audience \emph{is} the
Condemned. Mechanization of content review via \V{AI} apparently makes the
nano-targetting of just one user per performance cost-effective. To keep things
interesting, the cast of one also is the Condemned. They even get to make a
substantive choice, to determine the duration of the performance: Hours if they
forgo appeal, days if they appeal, or forever if they walk out. Alas, it's
unclear what the word ``appeal'' in the previous sentence means. Since Twitter
limits justifications to 280 characters, keeps admonishing that ``you won't be
able to access your Twitter account'' and to ``just delete your content,''
provides no explanation for rejecting an appeal, and discloses no statistics in
its semiannual transparency reports (more on that in \S\ref{sec:census}),
``appeal'' becomes an unappealing husk of its usual self.

Taken together, the particulars of the punishing performance combine into an
intervention that is closer to a nightmare's twisted rendition of the Catholic
Inquisition~\cite{Lea1906a,Lea1906b,Lea1906c,Lea1906d} or Maoist denunciation
rallies~\cite{Yang2021} than a governance function. At the same time, the
\V{AI}-based personalization of the performance avoids the power-eroding
downsides identified by Foucault. From a humanitarian viewpoint, Twitter's
performance also avoids the violence and torture pervasive amongst its
historical precedents---though that may just be because emotional abuse is the
only feasible abuse in the virtuality of the internet. Meanwhile, the
nano-targeting makes the performance resilient to outside interference. After
all, the vast majority of Twitter users will never experience it. If pressed,
they can always reassure themselves with Twitter's oh so reasonable policies,
whereas any trace of hurt or anger makes a Condemned come across as the
opposite, that is, positively unreasonable, if not hysterical---and hence so
much easier to dismiss and ignore.

Still, the lack of physical force and torture does raise the question of why
anyone would ever put up with that shit. The reason was pre-Musk Twitter's
rather unique position as breaking news service, political townsquare,
professional society, and corporate customer service platform in one. Thanks to
that combination, the threat of account termination was substantial and,
depending on a user's Twitter presence, could approach something like real-world
social death. However, thanks to Mr Musk's ``extremely hardcore'' leadership
since taking over the firm~\cite{SchifferNewtonea2023}, Twitter lost plenty of
users and advertisers. Worse, Mr Musk insists not only on running the social
network according to his ever-changing whims, but also must be the most visible
user, dominating notifications. Hence a return to old form seems impossible.


\subsection{Twitter's Neutrality and Trustworthiness}
\label{sec:trusting-twitter}

The cognitive dissonance between Twitter's measured policy and its punishing,
performative enforcement may seem extreme at first and make one wonder about the
kind of (dysfunctional) firm culture that tolerates such obviously divergent
practices. But it doesn't take much to get there. The very dehumanizing
condescencion engendered in the punishing performance points to this being just
another case of othering, of us versus them. Twitter employees felt like the
good guys keeping daily active shitheads in check, which licensed them to
gradually dehumanize the shitheads. Nonetheless, the dissonance is deeply
corrosive and raises significant doubts about Twitter's trustworthiness and
integrity.

It doesn't help that content policies, their enforcement, and their transparency
data are almost entirely silent on a critical salient feature. They hardly
mention the use of \V{AI}. Yet that use is not new and dates back to the
beginning of the pandemic at the very least~\cite{ScottKayali2020}. Clearly, the
firm had plenty of time to update its documentation. Worse, that omission isn't
limited to content policy etc, but extends to \emph{all} of Twitter's help
pages. Table~\ref{table:search} quantifies the number of results from searching
for common variations of the term ``\V{AI}'' using Twitter's own search
functionality. The darth of relevant material is striking. Not only were there
hardly any mentions, but existing ones amounted to little more than
acknowledgements that, for instance, top tweets, topics, and recommendations are
curated algorithmically. There certainly were no context-providing dataset,
model, or system cards to be
found~\cite{GebruMorgensternea2021,MitchellWuea2019,ProcopeCheemaea2022}. So
much for Twitter's stated commitment to
implementing the Santa Clara Principles, which require detailed disclosure of
automated content
moderation~\cite{AccessNowACLUFoundationOfNorthernCaliforniaea2021}.

\begin{table}
\caption{Search terms and number of hits on Twitter's help pages (as of 21
    October, 2022)}
\label{table:search}
\libertineLF
\begin{tabular}{lr}
\textbf{Search Term} & \textbf{Results} \B \\ \hline
AI & \T0 \\
algorithm & 5 \\
artificial intelligence & 1 \\
machine learning & 3 \\
\end{tabular}
\end{table}

Twitter's transparency report nonetheless helps confirm an important aspect of
its automated content review, namely the exact timing. When my account was
blocked in October 2021, the notification thereof was nearly instantaneous after
posting, but I wasn't entirely sure whether Twitter's application had confirmed
the posting of my violative tweet. This matters since Twitter reviewing all
content before posting also eliminates any notion of human harm and thereby the
justification for punishment. I made that a major point in my appeals. Alas, it
appears that Twitter's systems perform posting and reviewing tasks in parallel.
In its reporting, Twitter uses the rather imprecise bands of <100, 100--1,000,
and >1,000 views before content removal~\cite{Twitter2021}. In contrast,
Pinterest uses bands 0, 1--9, 10--100, and >100 views~\cite{Pinterest2022} and
YouTube uses bands 0, 1--10, and >100 views~\cite{Google2022}. Clearly, the
latter two social media are confident in their proactive content removal,
whereas Twitter is not.

Note that user-initiated content review moves at a much slower pace. I reported
a tweet by a news organization that seemed to wish a fate not unlike the one I
had in mind for oil company \V{CEO}s on the Parkland school shooter after his
sentencing to life in prison~\cite{ShapiroDeliso2022}. Twitter took about eight
hours to respond with a decision. Not surprisingly, the firm rejected that
complaint. While another tweet would have made for a closer equivalence, that
tweet was posted by a regular individual. But given the deeply problematic
implications of flagging~\cite{CrawfordGillespie2016}, reporting that tweet
seemed unethical.

Finally, Elon Musk's reign has resulted in further evidence that the Twitter of
yore was not trustworthy. Much of the reporting under the banner of ``Twitter
files,'' including most of Matt Taibbi's tweets, suffer from breathless
overclaims and hence are a bit hard to take. However, the Free Press'
investigation into secret blacklists, including for supposed Covid-19
misinformation that wasn't really misinformation, raises uncomfortable concerns
about heavyhanded over-moderation and a lack of transparency encouraging
abuse~\cite{WeissShrierea2022,Zweig2022}. Then again, the fact that Twitter's
new head of trust, Ella Irwin, is shown casually using ``goddess mode,'' a
special user interface that enables her to impersonate \emph{any} user and post
content under their identity, does not reflect well on Mr Musk's commitment to
security and privacy for the platform.
