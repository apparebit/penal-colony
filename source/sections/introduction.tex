% Per epigraph's documentation, the new environment gives us indented paragraphs
% and justified text.
\newenvironment{kafkaesque}{
    \setlength{\parindent}{\normalparindent}
}{}
\renewcommand{\textflush}{kafkaesque}
\setlength{\epigraphwidth}{0.8\textwidth}

\epigraph{\noindent\openfat{}As you see, it consists of three parts. With the
passage of time certain popular names have been developed for each of these
parts. The one underneath is called the Bed, the upper one is called the
Inscriber, and here in the middle, this moving part is called the Harrow.
[\ldots]

As soon as the man is strapped in securely, the Bed is set in motion. It quivers
with tiny, very rapid oscillations from side to side and up and down
simultaneously. [\ldots] Only with our Bed all movements are precisely
calibrated, for they must be meticulously coordinated with the movements of the
Harrow. But it's the Harrow which has the job of actually carrying out the
sentence. [\ldots]

The law which a condemned man has violated is inscribed on his body with the
Harrow.\closefat}{Franz Kafka, \emph{In the Penal Colony}~\cite{Kafka1995}}


\section{Introduction}
\label{sec:introduction}

My first interaction with \DALLE~2, OpenAI's headline-making text-to-image
system, in late July 2022 didn't quite go as expected. I had signed up with
OpenAI several months before but had been granted access only earlier that day.
So I was eager to try out the system and started with a prompt that had yielded
good results with another text-to-image system. But instead of producing four
images, \DALLE~2 responded with a stern warning:

\begin{quote}
\openfat{}It looks like this request may not follow our content policy. Further
policy violations may lead to an automatic suspension of your
account.\closefat{}
\end{quote}

\noindent Whoa! I enter an entirely reasonable prompt and OpenAI immediately
threatens me with account suspension? Without even telling me what I did wrong?
That's just ridiculous. And frustrating. Consulting the content policy didn't
help much either. The policy seemed broad, also vague. I eventually did narrow
down the violation to two out of the eleven content prohibitions. But which of
the two? I couldn't tell. It all seemed rather Kafkaesque!

It also was familiar. In October 2021, Twitter's \AI\ took offense to an
admittedly caustic tweet I had just posted and locked down my account. A first
appeal was rejected without filling in the placeholders of the email
notification template and hence without any justification. A second appeal was
still pending three weeks later. All along, my Twitter experience was reduced to
nothing but that same tweet, nicely centered on screen. At that point, I had
enough of single tweet limbo and did submit to Twitter's penance rites: I
withdrew my appeal, acknowledged that I ``violated the Twitter Rules,'' and
deleted the offending tweet --- all with one click on the red ``Delete'' button.

While the two interventions were substantially different, I experienced the
respective enforcement processes as similarly punitive, with little
consideration given to my voice, agency, and dignity. Moreover, my prompt to
\DALLE{} was intercepted before generating images; generated images, in turn, are
not publicly visible. Similarly, my tweet was taken down within a couple of
seconds after posting at most. Given the limited reach of my Twitter account,
which had barely 140 followers at the time, and the early hour, just before
6$\,$am on the East coast, I very much doubt that anyone ever saw the tweet ---
besides me. In short, thanks to algorithmic content moderation no-one could have
been harmed by prompt or tweet. But that also renders any justification for
meting out punishment null and void.

When \DALLE{} threatened me with account suspension, I immediately recognized
the punitive thrust shared with Twitter's content moderation and became curious
about the extent of such punitive algorithmic interventions. This paper is a
first attempt to map just that extent. In doing so, I focus on content
moderation, which arguably is \emph{the} business value proposition of social
media~\cite{Masnick2022a,Patel2022a} and lately of considerable public interest.

At the same time, there is no shortage of effectively punitive algorithmic
interventions. Examples include credit scoring~\cite{Anonymous2018}, debt
assessment~\cite{Yampolskiy2015}, exam proctoring~\cite{FrancisWard2021b}, fraud
prevention~\cite{Kugel2022}, grading~\cite{Lam2020}, job and school
applications~\cite{Anonymous2016,Hall2012,Hall2020a,Stockton2020}, personal
vendettas~\cite{Casovan2022}, private security services~\cite{HaoSwart2022},
productivity
monitoring~\cite{Covert2022,HaoFreischlad2022,KantorSundaramea2022,Rosenblat2018},
and screening for child sexual abuse materials or \CSAM~\cite{Atherton2022a}.
Still, Amazon's warehouses stand out for their profit-driven
amorality~\cite{KantorWeiseea2021,Lennard2020}: The firm's ruthless algorithmic
exploitation of its workers not only leads to high injury
rates~\cite{Brown2019a,Clark2023,Sainato2021}, but the resulting 150\% yearly
staff turnover means that Amazon will run out of people to exploit over the next
few years~\cite{Sainato2022}.

I call the conceptual space of punitive algorithms the \emph{stochastic penal
colony}. To provide a first map of that space, this paper first explores
OpenAI's enforcement process in \S\ref{sec:dalle} and then Twitter's in
\S\ref{sec:tweet-da-fe}. For each firm, it leverages a close textual reading of
firm policies and other communications to enumerate the many ways its
enforcement process deprives targeted users of voice, agency, and dignity. It
also contrasts these \emph{Kafkaesque co-factors} with major failures of neutral
and trustworthy content moderation.

\S\ref{sec:census} shifts from auto-ethnographic case studies based on
procedural justice~\cite{Tyler2003,Tyler2006,Tyler2007} to a cumulative
perspective, performing a comprehensive comparison of popular non-Chinese social
media and their governance based on their transparency reports. Results suggest
that content moderation is excessively punitive across all social media
platforms. Telegram is the only exception, but only because it doesn't perform
meaningful content moderation. Furthermore, social media governance still is far
from accountable, with transparency reports addressing zero to ten criteria out
of the fourteen I identified. \S\ref{sec:census-validation} explores the
validity of transparency data by comparing disclosures by Google, Meta, and the
National Center for Missing an Exploited Children and \S\ref{sec:census-limits}
explores on the example of industry-leading Meta how hypergrowth as business
strategy has directly contributed to devastating human harm. Alas this lack of
transparency and accountability may just come to an end this year. The \EU's
Digital Services Act provides a future baseline by enumerating the metrics
internet platforms must include in their independently audited, yearly reports.

Whereas the census in \S\ref{sec:census} takes a broad view, \S\ref{sec:escape}
goes deep again by experimentally exploring the reason for my first prompt's
rejection as well as my successful strategy for circumventing \DALLE's content
moderation. Since I did seek to create violative content related to the topics
of this paper but have little tolerance for realistic gore, I restricted myself
to images that would be suitable as editorial content for a magazine version of
this paper. Thanks to that restriction, images are not substantially more
disturbing than a Francis Bacon painting and I include highlights in
Appendix~\ref{app:dalle-images} starting on page~\pageref{app:dalle-images}.

The hands-on investigation of \DALLE\ surepitiously surfaced two additional
limitations of OpenAI's content policy and automated enforcement. First, \DALLE\
effectively discriminated against Christian religious beliefs, simultaneously
censoring too little and too much, with the latter including the crucifixion.
Between me running these experiments in August through October 2022 mostly and
completing this paper in February 2023, OpenAI has updated its censor and now
accepts the crucifixion and hence is not as discriminatory anymore. Second,
OpenAI's post-processing of prompts to diversify gender and race representation
is outright dangerous~\cite{OpenAI2022e,Sparkes2022}. In particular, it appears
to be the main trigger for some prompts yielding grotesquely racist imagery.
Worse, once I knew what to look for, I recognized similar, though less
pronounced effects in earlier generations. These images are \emph{not}
reproduced in this paper or its appendices; though they are included with the
supplemental materials at \url{https://github.com/apparebit/penal-colony}.

In \S\ref{sec:discussion}, I pull together key results from previous sections
and demonstrate that, overall, social media governance is a shambles: Policies
run counter the public interest. Enforcement is mostly punitive. Transparency
disclosures are incomplete, incorrect, and unaudited. None of this is new: All
but one of the surveyed platforms were launched betwee one and two decades ago.
If social media firms haven't been capable of fixing this on their own, they
won't do so in the future and aggressive regulation of the industry is long
overdue. I explore the issue of hands-on experimentation in some detail and
propose an approach loosely based on patent law to legally require that
researchers be given access to machine learning models. Finally,
\S\ref{sec:conclusion} concludes this paper with an appeal to the one principle
that holds promise for ameliorating life in the stochastic penal colony, harm
reduction. Appendices~\ref{app:dalle-sources}--\ref{app:chatgpt} reproduce
relevant source materials, whereas Appendix~\ref{app:research-ethics} discusses
researches ethics, including potential conflicts of interest.

Before diving into the substance of this pointed critique of algorithmic
interventions, \S\ref{sec:context} covers the conceptual, political, historical,
and literary context of the stochastic penal colony and \S\ref{sec:criteria}
grounds my narrative technique for identifying punitive aspects of content
moderation, \emph{Kafkaesque co-factors}, in procedural justice. Coincidentally,
that also enables me to provide a more precise definition of the stochastic
penal colony.


\subsection{Conceptual, Political, Historical, and Literary Context}
\label{sec:context}

In \emph{Discipline and Punish}, Foucault traces the transition from punishment
as a public and usually deadly spectacle to the modern prison and other
disciplinary institutions~\cite{Foucault1979}. He argues that this transition
did not happen for humanist concerns, as the result of reform efforts. Instead,
the driving force was the destabilizing impact of public executions. By being
rather ostentatious displays of power, they turned the criminal into sympathetic
victim. In contrast, executioner as well as sovereign became targets of popular
resentment. By simultaneously rationalizing, tempering, and distributing the
application of power, penal institutions avoid these downsides. They instead
instill discipline into the individual under their custody. As people
internalize discipline, that self-discipline obviates the need for more direct
applications of power and begets other disciplinary institutions, including
schools, hospitals, and factories. That way, we all turned into seasoned
practitioners of discipline.

The institutionalization of discipline does place constraints on the sovereign's
exercise of power and leads to an attendant loss of centralized control. That
last aspect is often lost on Foucault's readers. They are so razzle-dazzled by
Foucault's (admittedly fascinating) idealized disciplinary institution, the
panopticon, they don't realize that such a circular arrangement of cells around
a central monitoring station or tower simply can't scale beyond maybe 500 cells
--- at least in an architectural reality dominated by steel and concrete. Alas,
with the advent of cheap hardware sensors and powerful machine learning models,
re-centralizing control through ubiquitous digital surveillance is becoming
practical. While East Germany did manage just that for 40 years, its lo-tech
approach to central control was too expensive to be sustainable in the long run.
In one district, 18\% of the population were active informants for the Stasi,
that country's vicious state security service~\cite{Kellerhoff2022}.

In contrast, China under its current, particularly authoritarian president Xi
Jinping --- or more concisely Xina --- is reaping the benefits of readily
available sensors and algorithms. By rolling out ever more intrusive yet
centralized control, Xina is erasing the distinction between prison and
not-prison at scale~\cite{Grauer2021,MozurXiaoea2022,SmithIV2016}. Ironically,
some of that is driven by American innovations on predictive
policing~\cite{PerryMcInnisea2013,SmithIV2016,Sprick2019}. But the excessive
intrusiveness of the Han n\'ee Borg declaring ``Resistance is futile. You will
be assimilated!'' also makes Xina's \emph{surveillance state} an unsuitable
model for algorithmic control in western democracies.

The \emph{carceral state} in the United States comes closer~\cite{Simon2007}. It
has the largest number of prisoners in the world — as of 2022, the country
accounted for 4.25\% of the world population~\cite{Worldometer2023} and 20\% of
people in prisons or jails across the world~\cite{SawyerWagner2022} — and the
highest incarceration rate in the world — at 625 per 100,000 in 2019, the US
imprisoned 6.0$\mspace{1mu}\times$ as many people as Canada,
9.4$\mspace{1mu}\times$ as Germany, and 17.5$\mspace{1mu}\times$ as
Japan~\cite{WorldPrisonBrief2023}. Additionally, roughly double as many people
are under the control of the carceral state through probation or parole and may
be locked up at a moment's notice for largely arbitrary
reasons~\cite{SawyerWagner2022}. Next, many of the imprisoned are not there
because they have been convicted of a crime: Half of those imprisoned in local
jails (as opposed to federal prisons) are there for pretrial
detention~\cite{SawyerWagner2022}.

Worse, mass incarceration disproportionally impacts poor and minority
populations. Notably, Black Americans made up 12\% of the US adult population in
2018 but also made up 33\% of all people serving sentences greater than one year
in state or federal prison~\cite{Gramlich2020}. Incredibly, that is after a 34\%
reduction of their incarceration rate since 2006 and comparatively smaller
reductions for other ethnicities. They also tend to be locked up, far from home,
in districts that are far more white than their homes, cutting them off from
family and friends~\cite{WagnerKopf2015}.

As I'll discuss in more detail in Section~\ref{sec:census}, some of the more
extreme and hence also white supremacist practices of the American carceral
state, notably the (figurative) death penalty and three strikes rules, have
direct equivalents in social media content moderation. In the opposite
direction, the carceral state is an early and aggressive adopter of algorithmic
enforcement
technologies~\cite{AngwinLarsonea2016,EPIC2020,Hao2019,ReddenODonovanDixea2020,Yampolskiy2016}.
At the same time, algorithmic enforcement clearly isn't limited to the
government. Corporations and universities are deploying punitive interventions
just as well outside the criminal injustice system. In doing so, they may even
innovate on punishment. As I'll show in \S\ref{sec:tweet-da-fe}, Twitter's
enforcement process harkens back to punishment as a performance, but it does so
while (ingeniously) avoiding the destabilizing public spectacle. In short, this
paper is concerned with algorithmic interventions outside of the immediate
control of the sovereign state. That also distinguishes this work from previous
papers, which point towards the punitive potential but do so in the context of
the surveillance and carceral
states~\cite{DehlendorfGerety2021,McElroyWhittakerea2021}.

I am proposing the \emph{penal colony} as closest historical precedent and as
fitting model for contemporary algorithmic practices outside the criminal
injustice system. The French version of \emph{transportation} --- the practice
of sending prisoners to far locales --- is far more recent than we'd probably
like to acknowledge. France began turning French Guiana into one large penal
colony from 1852 onwards --- after the British had already begun unwinding
theirs --- and closed the colony only in
1953~\cite{Aldrich2010,Anderson2018,Spierenburg2009}. For the last 70 years or
so, transportation was reserved for convicts sentenced under France's own three
strikes laws. It also was almost always terminal: Only 2,000 out of 70,000
prisoners returned to France during their
lifetimes~\cite{WallechinskyWallace1978}. For that reason, prisoners referred to
the penal colony as ``dry guillotine''~\cite{Furlong1913,ReneBelbenoit1938}. Yet
discipline was surprisingly inconsistent, even lax, depending on location.

Foucault had surprisingly little to say about the penal
colony~\cite{Redfield2005}, even though transportation must be understood as a
distinct intermediate stage in penal history. As such, it combines aspects from
the performance of punishment and the discipline of prisons. Notably, like
earlier practices, transportation is usually terminal. But unlike earlier
practices, the penal colony is discretely out of sight. The penal colony also
incorporates a disciplinary component, typically involving hands-on labor to
create the infrastructure for more general colonization. The \emph{stochastic
penal colony} preserves that distinctness and stands apart from both carceral
and surveillance states. Its excessiveness does remind of the American carceral
state and its technology is much the same as Xina's surveillance state. But
there also is no central control or even intent. And while its downsides,
predictably, worsen along racial lines, it ensnares the privileged, including
many White people, almost as easily.

The remoteness of the penal colony, both literally and figuratively, also turns
it into an effective investigative device that renders contemporary practice
strange again and hence amenable to analysis. While that renders the stochastic
penal colony a largely ahistorical concept, its intellectual lineage does trace
right back to the former penal colony in French Guiana: The stochastic penal
colony obviously draws on Franz Kafka's 1919 short story \emph{In the Penal
Colony}~\cite{Kafka1995}. Kafka, in turn, was influenced~\cite{Robertson2017} by
Octave Mirbeau's 1899 novel \emph{The Torture Garden}~\cite{Mirbeau2008}. While
taking place in an imaginary China, its year of publication and dedication ---
``To Priests, Soldiers, Judges / to mean who rear, lead, or govern men / I
dedicate these pages of murder and blood.'' --- point to the Dreyfus affair as
primary inspiration. Alfred Dreyfus, a Jew and French military officer, had been
falsely convicted for espionage in early 1895 and again in 1899 --- with rampant
antisemitism leading to the systematic suppression of exculpatory evidence and
complete disregard of the real spy's public confession in 1898. As a result, Mr
Dreyfus spent 1895--1899 on Devil's Island, a particularly harsh location in the
French Guianan penal colony just off the coast. Coincidentally, the Dreyfus
affair also popularized the word ``intellectual,'' albeit starting out as a
pejorative~\cite{Drake2005,StudentsAtTheUniversityOfBristol2021}.

Besides, the stochastic penal colony~\emo{desert-island} provides an excellent
home for a pandemonium of stochastic
parrots~\emo{parrot}~\cite{BenderGebruea2021}!


\subsection{Foundational Criteria}
\label{sec:criteria}

In the auto-ethnographic case studies in the following two sections, I focus on
the procedural aspects of policy enforcement. In part, that reflects the fact
that the outcomes aren't particularly interesting. I still have both accounts
and they both still work. In part, that reflects the fact that I, just like the
people observed by Tyler and others, evaluate the justice of an intervention
based on its process. That endorsement is in fact based on an inadvertent
experimental outcome: I only learned of Tyler's work after having performed a
basic procedural justice analysis.

As already mentioned above, my analysis labels violations of a user's voice,
agency, and dignity as Kafkaesque co-factors and also considers violations of
neutrality and trust while considering additional sources. Procedural justice
positions voice and neutrality for evaluating the process itself, while respect
and trust are positioned for evaluating the relationships between participants.
If we disregard my playful labelling of ``Kafkaesque co-factors'' and rename
``dignity'' with ``respect,'' the similarities are obvious.

So is the primary difference: my inclusion of agency in addition to voice. Voice
means being listened to and given due consideration. Agency means the freedom to
make one's own decisions and then act on them, with an emphasis on the freedom
to act part. In other words, agency implies initiative whereas voice does not.
The omission of agency from procedural justice isn't too surprising when we
consider its original context, namely sovereign law and justice. In the
governmental application of justice and particularly in criminal justice,
individuals' agency is at best a secondary concern and for the most part
lacking. As the above summary of outcomes for the American application of
injustice demonstrates, even voice is on exceedingly shaky grounds in the US.

A more subtle difference is my grouping of the five criteria. Whereas procedural
justice distinguishes between process and relational criteria, I distinguish
between criteria that stand on their own and hence are meaningful even when
applied to just a single governance process, i.e., voice, agency, and dignity,
as well as criteria that require additional context, i.e., neutrality and trust.
Clearly, a negative individual experience will influence one's evaluation of
neutrality and trust as well. But being confident in statements about neutrality
and trust when it comes to governance procedures fundamentally requires more
than just one exemplar.

Having clarified the differences in criteria, I can now also give a better
definition of the stochastic penal colony: It's the universe of algorithmic
interventions outside the governmental application of justice that routinely
violate voice, agency, dignity, neutrality, and trust. That in turn also helps
clarify the distinction from Foucault's disciplinary institutions: The latter
imply some compromises when it comes to voice, agency, and dignity. But in the
modern conception, they also require neutrality and trust. Routine violations of
the latter two turn a disciplinary intervention into a penal one. For those same
reasons, the American carceral state is not a disciplinary institution in line
with Foucault's understanding but something altogether worse.
